http://web.archive.org/web/20140808001310id_/http://www.cnn.com:80/2014/07/01/opinion/weinberger-facebook

-- many people are outraged about the just - revealed psychological experiment @entity3 performed in 2012 on 690,000 unwitting people , altering the mix of positive and negative posts in their feeds			1
playing with people 's emotions without their consent is a problem			2
but it would be even worse if we think -- after @entity3 posts one of its all - too - common apologies -- that @entity3 is done manipulating its users			1
no. the experiment was only a more intrusive version of what the company does every time we visit our @entity3 page			1
@entity3 's experiment was a version of so - called " a / b " testing , one of the most widely used and effective techniques large websites use to " provide a better customer experience " -- that is , to sell us more stuff			1
for example , for years @entity31 has routinely experimented with seemingly insignificant changes to its pages , like showing half of its visitors a discount offer on the left side , and the same ad on the right to the other half			0
if @entity31 finds a statistically significant uptick in clicks on the offer when it 's on one side , from then on that 's where they put the offers			2
companies a / b test every parameter about a page , from font sizes to colors to the depth of the drop shadows			0
but the @entity3 experiment was not normal a / b testing			1
usually a test alters some seemingly irrelevant factor			0
but @entity3 's experiment changed the site 's core service : showing us what 's up with our friends			1
worse , @entity3 did so in a way likely to affect the emotional state of its users			1
and that 's something to be concerned about			2
but much of the outrage is driven by a false assumption : that there is a " real " mix of news about our friends			0
@entity3 always uses algorithms to figure out what to show us and what to leave obscure			1
@entity3 is in the business of providing us with a feed that filters the @entity87 rapids into a tinkling stream we can drink from			2
the 2012 experiment is a window onto this larger concern : @entity3 , an important and even dominant part of our social infrastructure , makes decisions about what we 'll know about our friends based on what works for @entity98 , and only secondarily based on what works for us as individuals and as a society			1
this point is illustrated in @entity104 's excellent book ( and terrific @entity105 ) the filter bubble			0
@entity3 filters our feeds to make us happier customers			2
but @entity3 defines a happy customer as one that comes back often and clicks on a lot of links			2
when it comes to politics , we can easily see the problem : showing us news that excites our click finger is a formula for promoting shouting and political divisiveness			0
too much of that is bad , but in both politics and social relationships more broadly , do we know what the " right mix " is ? are we sure that filtering social news so that it includes more of the negative is bad ? and positive filtering can paint a too - rosy picture of our social network , shielding us from the full force of life as it is actually lived			0
i do n't know the answer , but it ca n't come from a commercial entity whose overriding aim is to keep us coming back so we can buy more from its advertisers			0
there are many options to play with here			0
for example , we could be given more individual control over our own filters			0
or a site could " nudge " us toward feeds that achieve socially desirable aims like making us more willing to explore and embrace differences			0
but we 're unlikely to see such options so long as we have given control over our the flow of our social information to commercial entities that have as their primary interest not the health of our society and culture , but their bottom line			1
sometimes those interests may align , but not reliably or often enough			0
so , i 'm upset about @entity3 's cavalier toying with our emotions , but i 'm far more disturbed about what @entity3 and other such sites do all the time .			1

@entity169 : many angry over @entity3 's psychological experiment on users in 2012
he says it was only a more intrusive version of what @entity3 and other websites do all the time
@entity3 decides what we 'll know about friends based on what profits *fb* , he says
@entity169 : @entity3 could use this control to better society , but the bottom line comes first

@entity3:Facebook
@entity31:Amazon
@entity98:Facebook , Inc.
@entity0:CNN
@entity169:Weinberger
@entity104:Eli Pariser
@entity105:TED Talk
@entity87:Colorado River