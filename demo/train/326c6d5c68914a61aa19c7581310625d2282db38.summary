http://web.archive.org/web/20141104053545id_/http://www.cnn.com:80/2014/09/09/opinion/bostrom-machine-superintelligence

-- machines have surpassed humans in physical strength , speed and stamina			1
what would happen if machines surpassed human intellect as well ? the question is not just hypothetical ; we need to start taking this possibility seriously			1
most people might scoff at the prospect of machines outsmarting humanity			1
after all , even though today 's artificial intelligence can beat humans within narrow domains ( such as chess or trivia games ) , machine brains are still extremely rudimentary in general intelligence			2
machines currently lack the flexible learning and reasoning ability that enables an average human to master any of thousands of different occupations , as well as all the tasks of daily life			1
in particular , while computers are useful accessories to scientists , they are very , very far from doing the interesting parts of the research themselves			0
we know that evolutionary processes can produce human - level general intelligence , because they have already done so at least once in @entity41 's history			1
how quickly engineers achieve a similar feat is still an open question			0
by 2050 we may , according to a recent survey of leading artificial intelligence researchers , have a 50/50 chance of achieving human - level machine intelligence ( defined here as " one that can carry out most human professions at least as well as a typical human " )			1
even a cursory glance at technological development reveals multiple paths that could lead to human - level machine intelligence in this century			1
one likely path would be to continue studying the general properties of the human brain to decipher the computational structures it uses to generate intelligent behavior			2
another path would be the more mathematical " top - down " approach			2
and if somehow all the other approaches do n't work , scientists might simply brute - force the evolutionary process on computers			2
regardless of when and how we get there , the consequences of reaching human - level machine intelligence are profound , because human - level machine intelligence is not the final destination			1
machine intelligence would reach a recursive tipping point after which the design and improvement of such intelligence would no longer be in human hands			2
the next stop from human level intelligence , just a short distance farther along the tracks , is machine superintelligence			1
the train might not even decelerate at @entity87 : it is likely instead to swoosh right past			0
this brings us to what i think may well be the most important task of our time			0
if there will eventually be an " intelligence explosion , " how exactly can we set up the initial conditions so as to achieve an outcome that is survivable and beneficial to existing persons ? in " @entity101 : paths , dangers , strategies , " i focus on the dynamics of an intelligence explosion ; what will happen if and when we gain the ability to create machine superintelligence ? this topic is largely ignored and poorly funded			2
but we must keep at it : how could we engineer a controlled detonation that would protect human values from being overwritten by the arbitrary values of a misbegotten artificial superintelligence ? the picture that emerges from this work is fascinating and disconcerting			2
it looks like there are major existential risks associated with the creation of entities of greater - than - human intelligence			1
a superintelligence would n't even need to start with a physical embodiment to be catastrophically dangerous			0
major engineering projects and financial transactions on @entity41 are mediated by digital communication networks that would be at the mercy of an artificial superintelligence			2
placing an online order for an innocent - looking set of advanced blueprints or fooling its creators into thinking it is benign could be an initial step , followed by the possibility of permanently altering the global biosphere to pursue its preferences			0
the control problem — how to engineer a superintelligence to be safe and human - friendly — appears to be very difficult			1
it should be solvable in principle , but in practice it may not be solved in time for when the solution is needed			0
the difficulty is compounded by the need to get it right on the first try			0
an unfriendly superintelligence would not permit a mulligan			0
remember @entity152 from " 2001 : @entity153 " ? let 's try to avoid that			0
if we could solve the technical problem of constructing a motivation system that we can load with some terminal goal of our choosing , a further question remains : which goal would we give the superintelligent @entity163 ? much would hinge on that choice			1
in some scenarios , the first superintelligence becomes extremely powerful and shapes the entire future according to its preferences			0
we want an @entity163 that is safe , beneficial and ethical , but we do n't know exactly what that entails			1
some may think we have already arrived upon full moral enlightenment , but is is far more likely that we still have blind spots			0
our predecessors certainly had plenty -- in the practice of slavery and human sacrifice , or the condoning of manifold forms of brutality and oppression that would outrage the modern conscience			0
it would be a grave mistake to think we have reached our moral apogee , and thus lock our present - day ethics into such powerful machines			1
in this sense , we have philosophy with a deadline			0
our wisdom must precede our technology , and that which we value in life must be carefully articulated — or rather , it must be pointed to with the right mathematics — if it is to be the seed from which our intelligent creations grow .			0

@entity200 : what would happen if machines surpassed human intellect ?
@entity200 : by 2050 we may have a 50/50 chance of achieving human - level @entity163
he says we want an @entity163 that is safe and ethical , but it could get beyond our control
@entity200 : superintelligent machines could present major existential risks to humans

@entity163:A.I.
@entity0:CNN
@entity101:Superintelligence
@entity41:Earth
@entity87:Humanville Station
@entity153:A Space Odyssey
@entity152:HAL
@entity200:Bostrom